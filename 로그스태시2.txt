- mutate 플러그인의 옵션 및 적용 순서
coerce: null인 필드 값에 넣어줄 기본값을 지정한다.
rename: 필드 이름을 바꾼다.
replace: 필드 값을 특정 값으로 바꾼다.
gsub: 정규식 패턴이 일치하는 문자열을 다른 문자열로 대체한다.
uppercase: 필드 값을 모두 대문자로 변경한다.
lowercase: 필드 값을 모두 소문자로 변경한다.
strip: 필드 값의 좌우 공백을 제거한다.
join: 구분자를 지정해서 하나의 문자열로 합친다.
split: 구분자를 기준으로 문자열을 배열 형태로 나눈다.
merge: 특정 필드에 다른 필드를 포함시킨다.

============================================================================================================
logstash-test.conf 파일의 내용 수정
필터 플러그인 공통 옵션 추가
add_field 옵션은 새로운 필드를 추가한다.
split 옵션에 구분자에 의해 구분되어 배열 형태가 된 데이터에 특정 인덱스에 접근하려면 [필드이름][인덱스] 형식으로
접근하면 되고, 특정 인덱스의 값을 얻어오려면 %{[필드이름][인덱스]}와 같이 사용한다.
remove_field 옵션은 특정 필드를 삭제한다.
============================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
  mutate {
    split => {"message" => " "}
    add_field => {"id" => "%{[message][2]}"}
    remove_field => "message"
  }
}

output {
  stdout{ }
}
============================================================================================================

============================================================================================================
logstash-test2.conf 파일의 내용
filter 추가
dissect: mapping 옵션에 구분자 형태를 지정해서 필드를 구분한다.

%{필드명}와 같이 작성하면 %{ }안의 필드명으로 새로운 필드가 만들어지고, %{ } 외부의 문자들은 모두 구분자가 된다.
[%{timestamp}]^[%{id}]^%{ip}^%{port}^[%{level}]^-^%{message}. (구버전)
[%{timestamp}] [%{id}] %{ip} %{port} [%{level}] - %{message}. (신버전(공백하나))
[%{timestamp}]%{?->}[%{id}] %{ip} %{port} [%{level}] - %{message}. (신버전(연속공백))
[2023-11-01 12:52:12] [ID1] 192.168.0.7 9500 [INFO] - connected.
[2023-11-01 12:58:47]   [ID2] 218.35.17.184 1004 [warn] - busy server

[%{timestamp}]와 [%{id}] 사이에는 공백이 1칸인 경우와 공백이 3칸인 경우가 있다.
구분자를 만들 때 [%{timestamp}]와 [%{id}] 사이에 공백을 1칸을 주면 공백이 3칸인 로그에서 에러가 발생된다.
_dissectfailure 메시지는 dissect 플러그인이 에러가 발생되는 경우 발생한다.
이 문제를 해결하려면 공백이 몇 칸이 나오던지 공백을 무시하게 하면된다.
%{?->}로 지정하면 연속되는 여러 공백들을 무시한다.
============================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
   dissect {
     mapping => {"message" => "[%{timestamp}]%{?->}[%{id}] %{ip} %{port} [%{level}] - %{message}"}
  }
}

output {
  stdout{ }
}
============================================================================================================

============================================================================================================
logstash-test3.conf 파일의 내용
%{?필드명}와 같이 필드명 앞에 "?"를 붙여주거나 %{}만 입력하면 결과에 포함시키지 않는다.
%{+필드명}와 같이 필드명 앞에 "+"를 붙이면 %{}에 매핑된 내용을 "+"뒤에 지정한 필드에 붙인다.
%{ip} %{port} => ip 필드와 port 필드가 별도로 생성된다.
%{ip} %{+ip} => ip 필드의 값 뒤에 port 번호를 붙인다.
============================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
   dissect {
     mapping => {"message" => "[%{timestamp}]%{?->}[%{id}] %{ip} %{+ip} [%{?level}] - %{}"}
  }
}

output {
  stdout{ }
}
============================================================================================================

============================================================================================================
logstash-test4.conf 파일의 내용
filter 추가
grok: match 옵션에 정규 표현식 패턴을 지정해서 문자열을 파싱한다.
grok은 자주 사용하는 정규 표현식을 패턴화해놨으며 이 패턴을 이용해 %{패턴이름:필드명} 형태로 사용한다.
grok에 사용하는 정규 표현식 패턴은 아래의 주소를 참조한다.
https://github.com/logstash-plugins/logstash-patterns-core/blob/main/patterns/ecs-v1/grok-patterns

NUMBER: 십진수를 인식한다. 부호와 소수점도 포함한다.
SPACE: 공백, 탭 등 하나 이상의 공백을 인식한다.
URI: URI를 인식한다. 프로토콜, 인증 번호, 호스트, 경로, 파라미터를 포함할 수 있다.
IP: IP 주소를 인식한다. IPv4, IPv6를 모두 인식할 수 있다.
SYSLOGBASE: 시스로그 포맷에서 타임스템프, 중요도, 호스트, 프로세스 정보까지 인식한다.
TIMESTAMP_ISO8601: ISO8601 표준의 타임스템프를 인식한다. 2023-11-02T12:23:27+09:00의 형태이다.
DATA: 이 패턴의 직전 패턴부터 다음 패턴 사이를 모두 인식한다.

\[%{TIMESTAMP_ISO8601:timestamp}\]와 \[%{DATA:id}\] 사이에는 공백이 1칸인 경우와 공백이 3칸인 경우가 있다.
정규 표현식 패턴을 사용할 때 \[%{TIMESTAMP_ISO8601:timestamp}\]와 \[%{DATA:id}\] 사이에 공백을 1칸을 주면 
공백이 3칸인 로그에서 에러가 발생된다.
_grokparsefailure 메시지는 grok 플러그인이 에러가 발생되는 경우 발생한다.
이 문제를 해결하려면 공백이 몇 칸이 나오던지 공백을 무시하게 하면된다.
[ ]*로 지정하면 연속되는 여러 공백들을 무시한다.

"[", "]", "-", "."과 같은 기호는 역슬래시(\)를 붙여서 사용해야 한다.
NUMBER:ports의 결과를 엘라스틱서치에 저장하면 문자열 타입으로 인식된다. 정수 타입으로 엘라스틱서치에 저장할 때
인식하게 하려면 NUMBER:ports:int와 같이 :int를 추가하면 된다.
============================================================================================================
input {
  file {
    path => "C:/k_digital/elasticStack/logstash-7.17.14/filter-example.log"
    start_position => "beginning"
    sincedb_path => "nul"
  }
}

filter {
   grok {
     match => {"message" => "\[%{TIMESTAMP_ISO8601:timestamp}\] [ ]*\[%{DATA:id}\] %{IP:ip} %{NUMBER:port} \[%{LOGLEVEL:level}\] \- %{DATA:msg}\."}
  }
}

output {
  stdout{ }
}
============================================================================================================